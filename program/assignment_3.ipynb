{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a355287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b2265b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import ipytest\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession, LocalPipelineSession\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.workflow.parameters import ParameterInteger\n",
    "\n",
    "\n",
    "CODE_FOLDER = Path(\"code\")\n",
    "CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "INFERENCE_CODE_FOLDER = CODE_FOLDER / \"inference\"\n",
    "INFERENCE_CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.path.extend([f\"./{CODE_FOLDER}\", f\"./{INFERENCE_CODE_FOLDER}\"])\n",
    "\n",
    "DATA_FILEPATH = \"penguins.csv\"\n",
    "\n",
    "ipytest.autoconfig(raise_on_error=True)\n",
    "\n",
    "# By default, The SageMaker SDK logs events related to the default\n",
    "# configuration using the INFO level. To prevent these from spoiling\n",
    "# the output of this notebook cells, we can change the logging\n",
    "# level to ERROR instead.\n",
    "logging.getLogger(\"sagemaker.config\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3164a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LOCAL_MODE = False\n",
    "\n",
    "bucket = os.environ[\"BUCKET\"]\n",
    "role = os.environ[\"ROLE\"]\n",
    "\n",
    "S3_LOCATION = f\"s3://{bucket}/penguins\"\n",
    "\n",
    "architecture = !(uname -m)\n",
    "IS_APPLE_M_CHIP = architecture[0] == \"arm64\"\n",
    "\n",
    "\n",
    "pipeline_session = PipelineSession(default_bucket=bucket) if not LOCAL_MODE else None\n",
    "\n",
    "if LOCAL_MODE:\n",
    "    config = {\n",
    "        \"session\": LocalPipelineSession(default_bucket=bucket),\n",
    "        \"instance_type\": \"local\",\n",
    "        # We need to use a custom Docker image when we run the pipeline\n",
    "        # in Local Model on an ARM64 machine.\n",
    "        \"image\": \"sagemaker-tensorflow-toolkit-local\" if IS_APPLE_M_CHIP else None,\n",
    "    }\n",
    "else:\n",
    "    config = {\n",
    "        \"session\": pipeline_session,\n",
    "        \"instance_type\": \"ml.m5.xlarge\",\n",
    "        \"image\": None,\n",
    "    }\n",
    "\n",
    "config[\"framework_version\"] = \"2.11\"\n",
    "config[\"py_version\"] = \"py39\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "942a01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "iam_client = boto3.client(\"iam\")\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "USE_TUNING_STEP = not LOCAL_MODE\n",
    "# USE_TUNING_STEP = False and not LOCAL_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b18b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerryobex/proj/mlschool/.venv/lib/python3.9/site-packages/sagemaker/workflow/pipeline_context.py:297: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# | code: true\n",
    "# | output: false\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"15d\")\n",
    "\n",
    "# dataset_location = ParameterString(\n",
    "#     name=\"dataset_location\",\n",
    "#     default_value=f\"{S3_LOCATION}/data\",\n",
    "# )\n",
    "\n",
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=f\"{S3_LOCATION}/data\",\n",
    ")\n",
    "\n",
    "new_prep_processor = False\n",
    "\n",
    "processor = None\n",
    "\n",
    "if new_prep_processor:\n",
    "    # Specify the directory containing your `requirements.txt`\n",
    "    processor = FrameworkProcessor(\n",
    "        framework_version=\"1.2-1\",\n",
    "        estimator_cls=SKLearnProcessor,\n",
    "        base_job_name=\"preprocess-data\",\n",
    "        image_uri=retrieve(framework='sklearn', version='1.2-1', region=config[\"session\"].boto_region_name),\n",
    "        command=[\"python3\", \"-m\", \"preprocessor\"],\n",
    "        instance_type=config[\"instance_type\"],\n",
    "        instance_count=2,\n",
    "        role=role,\n",
    "        sagemaker_session=config[\"session\"],\n",
    "    )\n",
    "\n",
    "else:\n",
    "    processor = SKLearnProcessor(\n",
    "        base_job_name=\"preprocess-data\",\n",
    "        framework_version=\"1.2-1\",\n",
    "        # By default, a new account doesn't have access to `ml.m5.xlarge` instances.\n",
    "        # If you haven't requested a quota increase yet, you can use an\n",
    "        # `ml.t3.medium` instance type instead. This will work out of the box, but\n",
    "        # the Processing Job will take significantly longer than it should have.\n",
    "        # To get access to `ml.m5.xlarge` instances, you can request a quota\n",
    "        # increase under the Service Quotas section in your AWS account.\n",
    "        instance_type=config[\"instance_type\"],\n",
    "        instance_count=2,\n",
    "        role=role,\n",
    "        sagemaker_session=config[\"session\"],\n",
    "    )\n",
    "\n",
    "\n",
    "preprocessing_step = ProcessingStep(\n",
    "    name=\"preprocess-data\",\n",
    "    step_args=processor.run(\n",
    "        code=f\"{CODE_FOLDER}/preprocessor.py\",\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=dataset_location, destination=\"/opt/ml/processing/input\", s3_data_distribution_type=\"ShardedByS3Key\"\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"train\",\n",
    "                source=\"/opt/ml/processing/train\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/train\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"validation\",\n",
    "                source=\"/opt/ml/processing/validation\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/validation\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"test\",\n",
    "                source=\"/opt/ml/processing/test\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/test\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"model\",\n",
    "                source=\"/opt/ml/processing/model\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/model\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"train-baseline\",\n",
    "                source=\"/opt/ml/processing/train-baseline\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/train-baseline\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"test-baseline\",\n",
    "                source=\"/opt/ml/processing/test-baseline\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/test-baseline\",\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")\n",
    "\n",
    "\n",
    "epochs = ParameterInteger(name=\"epochs\", default_value=50)\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    base_job_name=\"training\",\n",
    "    entry_point=f\"{CODE_FOLDER}/train.py\",\n",
    "    # SageMaker will pass these hyperparameters as arguments\n",
    "    # to the entry point of the training script.\n",
    "    hyperparameters={\n",
    "        \"epochs\": epochs,  # Referencing the pipeline parameter\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 0.01,\n",
    "    },\n",
    "    # SageMaker will track these metrics as part of the experiment\n",
    "    # associated to this pipeline. The metric definitions tells\n",
    "    # SageMaker how to parse the values from the Training Job logs.\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"accuracy\", \"Regex\": \"accuracy: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"},\n",
    "    ],\n",
    "    image_uri=config[\"image\"],\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    py_version=config[\"py_version\"],\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    disable_profiler=True,\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "train_model_step = TrainingStep(\n",
    "    name=\"train-model\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    "    # cache_config is optional, shown here as part of a complete example\n",
    "    cache_config=cache_config  # Assuming cache_config is defined elsewhere\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ee3ab26-afa5-4ceb-9f7a-005d5fdea646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/evaluation_old.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/evaluation_old.py\n",
    "#| label: evaluation-script\n",
    "#| echo: true\n",
    "#| output: false\n",
    "#| filename: evaluation.py\n",
    "#| code-line-numbers: true\n",
    "\n",
    "import json\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def evaluate(model_path, test_path, output_path):\n",
    "    X_test = pd.read_csv(Path(test_path) / \"test.csv\")\n",
    "    y_test = X_test.iloc[:, -1]  # Assuming the last column is the target\n",
    "    island_columns = X_test.columns[-4:-1]  # Last 3 columns are one-hot encoded islands, excluding the target\n",
    "    X_test.drop(X_test.columns[-1], axis=1, inplace=True)  # Drop target column only\n",
    "\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    model = keras.models.load_model(Path(model_path) / \"001\")\n",
    "    \n",
    "    predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "    overall_accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Overall Test Accuracy: {overall_accuracy}\")\n",
    "\n",
    "    precision = precision_score(y_test, predictions, average=None, zero_division=0)\n",
    "    recall = recall_score(y_test, predictions, average=None, zero_division=0)\n",
    "    \n",
    "    # Print overall precision and recall\n",
    "    print(\"Overall Precision by Class:\", precision)\n",
    "    print(\"Overall Recall by Class:\", recall)\n",
    "\n",
    "    island_accuracies = {}\n",
    "    for col in island_columns:\n",
    "        island_mask = X_test[col] == 1\n",
    "        y_island = y_test[island_mask]\n",
    "        if len(y_island) > 0:\n",
    "            island_predictions = np.argmax(model.predict(X_test[island_mask]), axis=-1)\n",
    "            island_accuracy = accuracy_score(y_island, island_predictions)\n",
    "            island_accuracies[col] = island_accuracy\n",
    "            print(f\"Accuracy for island {col}: {island_accuracy}\")\n",
    "        else:\n",
    "            island_accuracies[col] = None\n",
    "            print(f\"No samples for {col}.\")\n",
    "\n",
    "    evaluation_report = {\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": {\"value\": overall_accuracy},\n",
    "            \"island_accuracies\": island_accuracies,\n",
    "            \"precision\": {f\"class_{i}\": val for i, val in enumerate(precision)},\n",
    "            \"recall\": {f\"class_{i}\": val for i, val in enumerate(recall)},\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=\"/opt/ml/processing/model/\", \n",
    "        test_path=\"/opt/ml/processing/test/\",\n",
    "        output_path=\"/opt/ml/processing/evaluation/\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a2540d8-278a-4953-bc54-0469d154427d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 1.0239 - accuracy: 0.5607 - val_loss: 1.0263 - val_accuracy: 0.6471 - 141ms/epoch - 18ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Validation accuracy: 0.6470588235294118\n",
      "INFO:tensorflow:Assets written to: /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmph6x_65ub/model/001/assets\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Overall Test Accuracy: 0.6078431372549019\n",
      "Overall Precision by Class: [0.69230769 0.26315789 0.89473684]\n",
      "Overall Recall by Class: [0.39130435 0.5        0.94444444]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Accuracy for island 0.0: 0.72\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Accuracy for island 1.0: 0.3333333333333333\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Accuracy for island 0.0.1: 0.875\n",
      "\u001b[32m.\u001b[0m8/8 - 0s - loss: 1.0713 - accuracy: 0.4519 - val_loss: 1.0650 - val_accuracy: 0.4314 - 179ms/epoch - 22ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Validation accuracy: 0.43137254901960786\n",
      "INFO:tensorflow:Assets written to: /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmp3jtu3si8/model/001/assets\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Overall Test Accuracy: 0.5098039215686274\n",
      "Overall Precision by Class: [0.83333333 0.         0.55172414]\n",
      "Overall Recall by Class: [0.43478261 0.         0.88888889]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Accuracy for island 0.0: 0.72\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Accuracy for island 1.0: 0.2222222222222222\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Accuracy for island 0.0.1: 0.5\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 1.11s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -s\n",
    "#| code-fold: true\n",
    "#| output: false\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import pytest\n",
    "import tempfile\n",
    "import joblib\n",
    "\n",
    "from preprocessor import preprocess\n",
    "from train import train\n",
    "from evaluation_old import evaluate\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "    \n",
    "    directory = Path(directory)\n",
    "    \n",
    "    preprocess(base_directory=directory)\n",
    "    \n",
    "    train(\n",
    "        model_directory=directory / \"model\",\n",
    "        train_path=directory / \"train\", \n",
    "        validation_path=directory / \"validation\",\n",
    "        epochs=1\n",
    "    )\n",
    "    \n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(directory / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(directory / \"model\" / \"001\", arcname=\"001\")\n",
    "        \n",
    "    evaluate(\n",
    "        model_path=directory, \n",
    "        test_path=directory / \"test\",\n",
    "        output_path=directory / \"evaluation\",\n",
    "    )\n",
    "\n",
    "    yield directory / \"evaluation\"\n",
    "    \n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "\n",
    "def test_evaluate_generates_evaluation_report(directory):\n",
    "    output = os.listdir(directory)\n",
    "    assert \"evaluation.json\" in output\n",
    "\n",
    "\n",
    "def test_evaluation_report_contains_accuracy(directory):\n",
    "    with open(directory / \"evaluation.json\", 'r') as file:\n",
    "        report = json.load(file)\n",
    "        \n",
    "    assert \"metrics\" in report\n",
    "    assert \"accuracy\" in report[\"metrics\"]\n",
    "    assert \"island_accuracies\" in report[\"metrics\"]\n",
    "    assert \"precision\" in report[\"metrics\"]\n",
    "    assert \"recall\" in report[\"metrics\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f03142d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/evaluation.py\n",
    "#| label: evaluation-script\n",
    "#| echo: true\n",
    "#| output: false\n",
    "#| filename: evaluation.py\n",
    "#| code-line-numbers: true\n",
    "\n",
    "import json\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def load_and_evaluate_model(model_path, X_test, y_test, island_columns):\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    model = keras.models.load_model(Path(model_path) / \"001\")\n",
    "    \n",
    "    predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "    overall_accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    precision = precision_score(y_test, predictions, average=None, zero_division=0)\n",
    "    recall = recall_score(y_test, predictions, average=None, zero_division=0)\n",
    "    \n",
    "    island_accuracies = {}\n",
    "    for col in island_columns:\n",
    "        island_mask = X_test[col] == 1\n",
    "        y_island = y_test[island_mask]\n",
    "        if len(y_island) > 0:\n",
    "            island_predictions = np.argmax(model.predict(X_test[island_mask]), axis=-1)\n",
    "            island_accuracy = accuracy_score(y_island, island_predictions)\n",
    "            island_accuracies[col] = island_accuracy\n",
    "        else:\n",
    "            island_accuracies[col] = None\n",
    "    \n",
    "    return overall_accuracy, island_accuracies, precision, recall\n",
    "\n",
    "def evaluate_models(trained_model_path, tuned_model_path, test_path, output_path):\n",
    "    X_test = pd.read_csv(Path(test_path) / \"test.csv\")\n",
    "    y_test = X_test.iloc[:, -1]  # Assuming the last column is the target\n",
    "    island_columns = X_test.columns[-4:-1]  # Last 3 columns are one-hot encoded islands, excluding the target\n",
    "    X_test.drop(X_test.columns[-1], axis=1, inplace=True)  # Drop target column only\n",
    "    \n",
    "    trained_model_accuracy, trained_island_accuracies, trained_precision, trained_recall = load_and_evaluate_model(trained_model_path, X_test, y_test, island_columns)\n",
    "    tuned_model_accuracy, tuned_island_accuracies, tuned_precision, tuned_recall = load_and_evaluate_model(tuned_model_path, X_test, y_test, island_columns)\n",
    "    \n",
    "    best_model, best_accuracy = (\"tuned\", tuned_model_accuracy) if tuned_model_accuracy > trained_model_accuracy else (\"trained\", trained_model_accuracy)\n",
    "    best_model_path = tuned_model_path if best_model == \"tuned\" else trained_model_path\n",
    "    \n",
    "    evaluation_report = {\n",
    "        \"best_model\": best_model,\n",
    "        \"best_model_accuracy\": best_accuracy,\n",
    "        \"best_model_path\": str(best_model_path),\n",
    "        \"comparison\": {\n",
    "            \"trained_model_accuracy\": trained_model_accuracy,\n",
    "            \"tuned_model_accuracy\": tuned_model_accuracy,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_models(\n",
    "        trained_model_path=\"/opt/ml/processing/trained_model/\",\n",
    "        tuned_model_path=\"/opt/ml/processing/tuned_model/\",\n",
    "        test_path=\"/opt/ml/processing/test/\",\n",
    "        output_path=\"/opt/ml/processing/evaluation/\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a6bf0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 1.1570 - accuracy: 0.4770 - val_loss: 0.9836 - val_accuracy: 0.4706 - 137ms/epoch - 17ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Validation accuracy: 0.47058823529411764\n",
      "INFO:tensorflow:Assets written to: /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmpj4dtiauk/model/001/assets\n",
      "\u001b[31mE\u001b[0m8/8 - 0s - loss: 0.9244 - accuracy: 0.5858 - val_loss: 0.8685 - val_accuracy: 0.7451 - 158ms/epoch - 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Validation accuracy: 0.7450980392156863\n",
      "INFO:tensorflow:Assets written to: /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmp89nx_6j5/model/001/assets\n",
      "\u001b[31mE\u001b[0m\n",
      "============================================== ERRORS ==============================================\n",
      "\u001b[31m\u001b[1m___________________ ERROR at setup of test_evaluate_generates_evaluation_report ____________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mfunction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, autouse=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mdirectory\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        directory = tempfile.mkdtemp()\u001b[90m\u001b[39;49;00m\n",
      "        input_directory = Path(directory) / \u001b[33m\"\u001b[39;49;00m\u001b[33minput\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        input_directory.mkdir(parents=\u001b[94mTrue\u001b[39;49;00m, exist_ok=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        shutil.copy2(DATA_FILEPATH, input_directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mdata.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        directory = Path(directory)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        preprocess(base_directory=directory)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        train(\u001b[90m\u001b[39;49;00m\n",
      "            model_directory=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            train_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            validation_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            epochs=\u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# After training a model, we need to prepare a package just like\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# SageMaker would. This package is what the evaluation script is\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# expecting as an input.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m tarfile.open(directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.tar.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mw:gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[94mas\u001b[39;49;00m tar:\u001b[90m\u001b[39;49;00m\n",
      "            tar.add(directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m / \u001b[33m\"\u001b[39;49;00m\u001b[33m001\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, arcname=\u001b[33m\"\u001b[39;49;00m\u001b[33m001\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# def evaluate_models(trained_model_path, tuned_model_path, test_path, output_path):\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       evaluate_models(\u001b[90m\u001b[39;49;00m\n",
      "            trained_model_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,  \u001b[90m# Path to the trained model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            tuned_model_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,  \u001b[90m# Path to the tuned model (simulated as the same for this test)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            test_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            output_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mevaluation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/ipykernel_23341/210011414.py\u001b[0m:41: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mcode/evaluation.py\u001b[0m:47: in evaluate_models\n",
      "    \u001b[0mtrained_model_accuracy, trained_island_accuracies, trained_precision, trained_recall = load_and_evaluate_model(trained_model_path, X_test, y_test, island_columns)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mcode/evaluation.py\u001b[0m:20: in load_and_evaluate_model\n",
      "    \u001b[0mmodel = keras.models.load_model(Path(model_path) / \u001b[33m\"\u001b[39;49;00m\u001b[33m1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)  \u001b[90m# Assuming model is in '1' directory\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../.venv/lib/python3.9/site-packages/keras/src/saving/saving_api.py\u001b[0m:262: in load_model\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m legacy_sm_saving_lib.load_model(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\u001b[0m:70: in error_handler\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m e.with_traceback(filtered_tb) \u001b[94mfrom\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "filepath = PosixPath('/var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmpj4dtiauk/model/1')\n",
      "custom_objects = {'Custom>Adadelta': <class 'keras.src.optimizers.adadelta.Adadelta'>, 'Custom>Adafactor': <class 'keras.src.optimizers...Adagrad': <class 'keras.src.optimizers.adagrad.Adagrad'>, 'Custom>Adam': <class 'keras.src.optimizers.adam.Adam'>, ...}\n",
      "compile = True, options = None\n",
      "\n",
      "    \u001b[0m\u001b[37m@traceback_utils\u001b[39;49;00m.filter_traceback\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mload_model\u001b[39;49;00m(filepath, custom_objects=\u001b[94mNone\u001b[39;49;00m, \u001b[96mcompile\u001b[39;49;00m=\u001b[94mTrue\u001b[39;49;00m, options=\u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Loads a model saved via `model.save()`.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Usage:\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    >>> model = tf.keras.Sequential([\u001b[39;49;00m\n",
      "    \u001b[33m    ...     tf.keras.layers.Dense(5, input_shape=(3,)),\u001b[39;49;00m\n",
      "    \u001b[33m    ...     tf.keras.layers.Softmax()])\u001b[39;49;00m\n",
      "    \u001b[33m    >>> model.save('/tmp/model')\u001b[39;49;00m\n",
      "    \u001b[33m    >>> loaded_model = tf.keras.models.load_model('/tmp/model')\u001b[39;49;00m\n",
      "    \u001b[33m    >>> x = tf.random.uniform((10, 3))\u001b[39;49;00m\n",
      "    \u001b[33m    >>> assert np.allclose(model.predict(x), loaded_model.predict(x))\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Note that the model weights may have different scoped names after being\u001b[39;49;00m\n",
      "    \u001b[33m    loaded. Scoped names include the model/layer names, such as\u001b[39;49;00m\n",
      "    \u001b[33m    `\"dense_1/kernel:0\"`. It is recommended that you use the layer properties to\u001b[39;49;00m\n",
      "    \u001b[33m    access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m        filepath: One of the following:\u001b[39;49;00m\n",
      "    \u001b[33m            - String or `pathlib.Path` object, path to the saved model\u001b[39;49;00m\n",
      "    \u001b[33m            - `h5py.File` object from which to load the model\u001b[39;49;00m\n",
      "    \u001b[33m        custom_objects: Optional dictionary mapping names\u001b[39;49;00m\n",
      "    \u001b[33m            (strings) to custom classes or functions to be\u001b[39;49;00m\n",
      "    \u001b[33m            considered during deserialization.\u001b[39;49;00m\n",
      "    \u001b[33m        compile: Boolean, whether to compile the model\u001b[39;49;00m\n",
      "    \u001b[33m            after loading.\u001b[39;49;00m\n",
      "    \u001b[33m        options: Optional `tf.saved_model.LoadOptions` object that specifies\u001b[39;49;00m\n",
      "    \u001b[33m          options for loading from SavedModel.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns:\u001b[39;49;00m\n",
      "    \u001b[33m        A Keras model instance. If the original model was compiled, and saved\u001b[39;49;00m\n",
      "    \u001b[33m        with the optimizer, then the returned model will be compiled. Otherwise,\u001b[39;49;00m\n",
      "    \u001b[33m        the model will be left uncompiled. In the case that an uncompiled model\u001b[39;49;00m\n",
      "    \u001b[33m        is returned, a warning is displayed if the `compile` argument is set to\u001b[39;49;00m\n",
      "    \u001b[33m        `True`.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Raises:\u001b[39;49;00m\n",
      "    \u001b[33m        ImportError: if loading from an hdf5 file and h5py is not available.\u001b[39;49;00m\n",
      "    \u001b[33m        IOError: In case of an invalid savefile.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m serialization.SharedObjectLoadingScope():\u001b[90m\u001b[39;49;00m\n",
      "            custom_objects = custom_objects \u001b[95mor\u001b[39;49;00m {}\u001b[90m\u001b[39;49;00m\n",
      "            tlco = object_registration._THREAD_LOCAL_CUSTOM_OBJECTS.\u001b[91m__dict__\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            gco = object_registration._GLOBAL_CUSTOM_OBJECTS\u001b[90m\u001b[39;49;00m\n",
      "            custom_objects = {**custom_objects, **tlco, **gco}\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m object_registration.CustomObjectScope(custom_objects):\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mwith\u001b[39;49;00m keras_option_scope(\u001b[90m\u001b[39;49;00m\n",
      "                    save_traces=\u001b[94mFalse\u001b[39;49;00m, in_tf_saved_model_scope=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mwith\u001b[39;49;00m load_context.load_context(options):\u001b[90m\u001b[39;49;00m\n",
      "                        filepath_str = io_utils.path_to_string(filepath)\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(filepath_str, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m tf.io.gfile.exists(filepath_str):\u001b[90m\u001b[39;49;00m\n",
      ">                               \u001b[94mraise\u001b[39;49;00m \u001b[96mIOError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mNo file or directory found at \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfilepath_str\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE                               OSError: No file or directory found at /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmpj4dtiauk/model/1\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../.venv/lib/python3.9/site-packages/keras/src/saving/legacy/save.py\u001b[0m:234: OSError\n",
      "---------------------------------------- Captured log setup ----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:801 Assets written to: /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmpj4dtiauk/model/001/assets\n",
      "\u001b[31m\u001b[1m____________________ ERROR at setup of test_evaluation_report_contains_accuracy ____________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mfunction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, autouse=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mdirectory\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        directory = tempfile.mkdtemp()\u001b[90m\u001b[39;49;00m\n",
      "        input_directory = Path(directory) / \u001b[33m\"\u001b[39;49;00m\u001b[33minput\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        input_directory.mkdir(parents=\u001b[94mTrue\u001b[39;49;00m, exist_ok=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        shutil.copy2(DATA_FILEPATH, input_directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mdata.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        directory = Path(directory)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        preprocess(base_directory=directory)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        train(\u001b[90m\u001b[39;49;00m\n",
      "            model_directory=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            train_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            validation_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            epochs=\u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# After training a model, we need to prepare a package just like\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# SageMaker would. This package is what the evaluation script is\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# expecting as an input.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m tarfile.open(directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.tar.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mw:gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[94mas\u001b[39;49;00m tar:\u001b[90m\u001b[39;49;00m\n",
      "            tar.add(directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m / \u001b[33m\"\u001b[39;49;00m\u001b[33m001\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, arcname=\u001b[33m\"\u001b[39;49;00m\u001b[33m001\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# def evaluate_models(trained_model_path, tuned_model_path, test_path, output_path):\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       evaluate_models(\u001b[90m\u001b[39;49;00m\n",
      "            trained_model_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,  \u001b[90m# Path to the trained model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            tuned_model_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,  \u001b[90m# Path to the tuned model (simulated as the same for this test)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            test_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            output_path=directory / \u001b[33m\"\u001b[39;49;00m\u001b[33mevaluation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/ipykernel_23341/210011414.py\u001b[0m:41: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mcode/evaluation.py\u001b[0m:47: in evaluate_models\n",
      "    \u001b[0mtrained_model_accuracy, trained_island_accuracies, trained_precision, trained_recall = load_and_evaluate_model(trained_model_path, X_test, y_test, island_columns)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mcode/evaluation.py\u001b[0m:20: in load_and_evaluate_model\n",
      "    \u001b[0mmodel = keras.models.load_model(Path(model_path) / \u001b[33m\"\u001b[39;49;00m\u001b[33m1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)  \u001b[90m# Assuming model is in '1' directory\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../.venv/lib/python3.9/site-packages/keras/src/saving/saving_api.py\u001b[0m:262: in load_model\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m legacy_sm_saving_lib.load_model(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\u001b[0m:70: in error_handler\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m e.with_traceback(filtered_tb) \u001b[94mfrom\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "filepath = PosixPath('/var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmp89nx_6j5/model/1')\n",
      "custom_objects = {'Custom>Adadelta': <class 'keras.src.optimizers.adadelta.Adadelta'>, 'Custom>Adafactor': <class 'keras.src.optimizers...Adagrad': <class 'keras.src.optimizers.adagrad.Adagrad'>, 'Custom>Adam': <class 'keras.src.optimizers.adam.Adam'>, ...}\n",
      "compile = True, options = None\n",
      "\n",
      "    \u001b[0m\u001b[37m@traceback_utils\u001b[39;49;00m.filter_traceback\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mload_model\u001b[39;49;00m(filepath, custom_objects=\u001b[94mNone\u001b[39;49;00m, \u001b[96mcompile\u001b[39;49;00m=\u001b[94mTrue\u001b[39;49;00m, options=\u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Loads a model saved via `model.save()`.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Usage:\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    >>> model = tf.keras.Sequential([\u001b[39;49;00m\n",
      "    \u001b[33m    ...     tf.keras.layers.Dense(5, input_shape=(3,)),\u001b[39;49;00m\n",
      "    \u001b[33m    ...     tf.keras.layers.Softmax()])\u001b[39;49;00m\n",
      "    \u001b[33m    >>> model.save('/tmp/model')\u001b[39;49;00m\n",
      "    \u001b[33m    >>> loaded_model = tf.keras.models.load_model('/tmp/model')\u001b[39;49;00m\n",
      "    \u001b[33m    >>> x = tf.random.uniform((10, 3))\u001b[39;49;00m\n",
      "    \u001b[33m    >>> assert np.allclose(model.predict(x), loaded_model.predict(x))\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Note that the model weights may have different scoped names after being\u001b[39;49;00m\n",
      "    \u001b[33m    loaded. Scoped names include the model/layer names, such as\u001b[39;49;00m\n",
      "    \u001b[33m    `\"dense_1/kernel:0\"`. It is recommended that you use the layer properties to\u001b[39;49;00m\n",
      "    \u001b[33m    access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m        filepath: One of the following:\u001b[39;49;00m\n",
      "    \u001b[33m            - String or `pathlib.Path` object, path to the saved model\u001b[39;49;00m\n",
      "    \u001b[33m            - `h5py.File` object from which to load the model\u001b[39;49;00m\n",
      "    \u001b[33m        custom_objects: Optional dictionary mapping names\u001b[39;49;00m\n",
      "    \u001b[33m            (strings) to custom classes or functions to be\u001b[39;49;00m\n",
      "    \u001b[33m            considered during deserialization.\u001b[39;49;00m\n",
      "    \u001b[33m        compile: Boolean, whether to compile the model\u001b[39;49;00m\n",
      "    \u001b[33m            after loading.\u001b[39;49;00m\n",
      "    \u001b[33m        options: Optional `tf.saved_model.LoadOptions` object that specifies\u001b[39;49;00m\n",
      "    \u001b[33m          options for loading from SavedModel.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns:\u001b[39;49;00m\n",
      "    \u001b[33m        A Keras model instance. If the original model was compiled, and saved\u001b[39;49;00m\n",
      "    \u001b[33m        with the optimizer, then the returned model will be compiled. Otherwise,\u001b[39;49;00m\n",
      "    \u001b[33m        the model will be left uncompiled. In the case that an uncompiled model\u001b[39;49;00m\n",
      "    \u001b[33m        is returned, a warning is displayed if the `compile` argument is set to\u001b[39;49;00m\n",
      "    \u001b[33m        `True`.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Raises:\u001b[39;49;00m\n",
      "    \u001b[33m        ImportError: if loading from an hdf5 file and h5py is not available.\u001b[39;49;00m\n",
      "    \u001b[33m        IOError: In case of an invalid savefile.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m serialization.SharedObjectLoadingScope():\u001b[90m\u001b[39;49;00m\n",
      "            custom_objects = custom_objects \u001b[95mor\u001b[39;49;00m {}\u001b[90m\u001b[39;49;00m\n",
      "            tlco = object_registration._THREAD_LOCAL_CUSTOM_OBJECTS.\u001b[91m__dict__\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            gco = object_registration._GLOBAL_CUSTOM_OBJECTS\u001b[90m\u001b[39;49;00m\n",
      "            custom_objects = {**custom_objects, **tlco, **gco}\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m object_registration.CustomObjectScope(custom_objects):\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mwith\u001b[39;49;00m keras_option_scope(\u001b[90m\u001b[39;49;00m\n",
      "                    save_traces=\u001b[94mFalse\u001b[39;49;00m, in_tf_saved_model_scope=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                ):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mwith\u001b[39;49;00m load_context.load_context(options):\u001b[90m\u001b[39;49;00m\n",
      "                        filepath_str = io_utils.path_to_string(filepath)\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(filepath_str, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m tf.io.gfile.exists(filepath_str):\u001b[90m\u001b[39;49;00m\n",
      ">                               \u001b[94mraise\u001b[39;49;00m \u001b[96mIOError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mNo file or directory found at \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfilepath_str\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE                               OSError: No file or directory found at /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmp89nx_6j5/model/1\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../.venv/lib/python3.9/site-packages/keras/src/saving/legacy/save.py\u001b[0m:234: OSError\n",
      "---------------------------------------- Captured log setup ----------------------------------------\n",
      "\u001b[32mINFO    \u001b[0m tensorflow:builder_impl.py:801 Assets written to: /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmp89nx_6j5/model/001/assets\n",
      "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m t_671aa09741ca4016b4fca8ec4e37ac5b.py::\u001b[1mtest_evaluate_generates_evaluation_report\u001b[0m - OSError: No file or directory found at /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmpj4dt...\n",
      "\u001b[31mERROR\u001b[0m t_671aa09741ca4016b4fca8ec4e37ac5b.py::\u001b[1mtest_evaluation_report_contains_accuracy\u001b[0m - OSError: No file or directory found at /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmp89nx...\n",
      "\u001b[31m\u001b[31m\u001b[1m2 errors\u001b[0m\u001b[31m in 0.79s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "ipytest failed with exit_code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mipytest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#| code-fold: true\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#| output: false\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport os\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport shutil\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport tarfile\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport pytest\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport tempfile\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mimport joblib\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom preprocessor import preprocess\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom train import train\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfrom evaluation import evaluate_models\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m@pytest.fixture(scope=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, autouse=False)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdef directory():\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    directory = tempfile.mkdtemp()\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    input_directory = Path(directory) / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    input_directory.mkdir(parents=True, exist_ok=True)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    shutil.copy2(DATA_FILEPATH, input_directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    directory = Path(directory)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    preprocess(base_directory=directory)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    train(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        model_directory=directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        train_path=directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        validation_path=directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        epochs=1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # After training a model, we need to prepare a package just like\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # SageMaker would. This package is what the evaluation script is\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # expecting as an input.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    with tarfile.open(directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.tar.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw:gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) as tar:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        tar.add(directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, arcname=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    # def evaluate_models(trained_model_path, tuned_model_path, test_path, output_path):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    evaluate_models(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        trained_model_path=directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,  # Path to the trained model\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        tuned_model_path=directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,  # Path to the tuned model (simulated as the same for this test)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        test_path=directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        output_path=directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    )\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    yield directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    shutil.rmtree(directory)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdef test_evaluate_generates_evaluation_report(directory):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    output = os.listdir(directory)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    assert \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m in output\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mdef test_evaluation_report_contains_accuracy(directory):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    with open(directory / \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m) as file:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        report = json.load(file)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    assert \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m in report\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    assert \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_model_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m in report\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    assert \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_model_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m in report\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    assert \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomparison\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m in report\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    assert \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrained_model_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m in report[\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomparison\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    assert \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtuned_model_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m in report[\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomparison\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/proj/mlschool/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/proj/mlschool/.venv/lib/python3.9/site-packages/ipytest/_impl.py:162\u001b[0m, in \u001b[0;36mpytest_magic\u001b[0;34m(line, cell, module)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe ipytest magic cannot evaluate the cell. Most likely you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare running a modified ipython version. Consider using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`ipytest.run` and `ipytest.clean` directly.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    158\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m--> 162\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrun_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrun_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/proj/mlschool/.venv/lib/python3.9/site-packages/ipytest/_impl.py:85\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(module, plugins, run_in_thread, raise_on_error, addopts, defopts, display_columns, *args)\u001b[0m\n\u001b[1;32m     82\u001b[0m ipytest\u001b[38;5;241m.\u001b[39mexit_code \u001b[38;5;241m=\u001b[39m exit_code\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_on_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exit_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(exit_code)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m exit_code\n",
      "\u001b[0;31mError\u001b[0m: ipytest failed with exit_code 1"
     ]
    }
   ],
   "source": [
    "%%ipytest -s\n",
    "#| code-fold: true\n",
    "#| output: false\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import pytest\n",
    "import tempfile\n",
    "import joblib\n",
    "\n",
    "from preprocessor import preprocess\n",
    "from train import train\n",
    "from evaluation import evaluate_models\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "    \n",
    "    directory = Path(directory)\n",
    "    \n",
    "    preprocess(base_directory=directory)\n",
    "    \n",
    "    train(\n",
    "        model_directory=directory / \"model\",\n",
    "        train_path=directory / \"train\", \n",
    "        validation_path=directory / \"validation\",\n",
    "        epochs=1\n",
    "    )\n",
    "    \n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(directory / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(directory / \"model\" / \"001\", arcname=\"001\")\n",
    "        \n",
    "    # def evaluate_models(trained_model_path, tuned_model_path, test_path, output_path):\n",
    "    evaluate_models(\n",
    "        trained_model_path=directory / \"model\",  # Path to the trained model\n",
    "        tuned_model_path=directory / \"model\",  # Path to the tuned model (simulated as the same for this test)\n",
    "        test_path=directory / \"test\",\n",
    "        output_path=directory / \"evaluation\",\n",
    "    )\n",
    "\n",
    "    yield directory / \"evaluation\"\n",
    "    \n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "\n",
    "def test_evaluate_generates_evaluation_report(directory):\n",
    "    output = os.listdir(directory)\n",
    "    assert \"evaluation.json\" in output\n",
    "\n",
    "\n",
    "def test_evaluation_report_contains_accuracy(directory):\n",
    "    with open(directory / \"evaluation.json\", 'r') as file:\n",
    "        report = json.load(file)\n",
    "        \n",
    "    assert \"best_model\" in report\n",
    "    assert \"best_model_accuracy\" in report\n",
    "    assert \"best_model_path\" in report\n",
    "    assert \"comparison\" in report\n",
    "    assert \"trained_model_accuracy\" in report[\"comparison\"]\n",
    "    assert \"tuned_model_accuracy\" in report[\"comparison\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f19e15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerryobex/proj/mlschool/.venv/lib/python3.9/site-packages/sagemaker/workflow/pipeline_context.py:297: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter, CategoricalParameter\n",
    "from sagemaker.tensorflow import TensorFlowProcessor\n",
    "\n",
    "evaluation_processor = TensorFlowProcessor(\n",
    "    base_job_name=\"evaluation-processor\",\n",
    "    image_uri=config[\"image\"],\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    py_version=config[\"py_version\"],\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "# target_metric_name = \"val_accuracy\"\n",
    "# objective_type=\"Maximize\",\n",
    "target_metric_name = \"loss\"\n",
    "objective_type=\"Minimize\",\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name=target_metric_name,\n",
    "    objective_type=objective_type,\n",
    "    hyperparameter_ranges={\n",
    "        'learning_rate': ContinuousParameter(0.001, 0.2),\n",
    "        \"epochs\": IntegerParameter(10, 50),\n",
    "    },\n",
    "    metric_definitions=[{\"Name\": target_metric_name, \"Regex\": f\"{target_metric_name}: ([0-9\\\\.]+)\"}],\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3,\n",
    ")\n",
    "\n",
    "tune_model_step = TuningStep(\n",
    "    name=\"tune-model\",\n",
    "    step_args=tuner.fit(\n",
    "        inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")\n",
    "model_assets = train_model_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "\n",
    "if USE_TUNING_STEP:\n",
    "    model_assets = tune_model_step.get_top_model_s3_uri(\n",
    "        top_k=0, s3_bucket=config[\"session\"].default_bucket()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9773a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve accuracy metric from the latest model package.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_payload_dict)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Use the output from Lambda as the accuracy threshold\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m accuracy_threshold \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_payload_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_model_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    114\u001b[0m latest_model_accuracy \u001b[38;5;241m=\u001b[39m JsonGet(\n\u001b[1;32m    115\u001b[0m     step_name\u001b[38;5;241m=\u001b[39mevaluate_model_step\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    116\u001b[0m     property_file\u001b[38;5;241m=\u001b[39mevaluation_report,\n\u001b[1;32m    117\u001b[0m     json_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics.accuracy.value\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    118\u001b[0m )\n\u001b[1;32m    120\u001b[0m fail_step \u001b[38;5;241m=\u001b[39m FailStep(\n\u001b[1;32m    121\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    122\u001b[0m     error_message\u001b[38;5;241m=\u001b[39mJoin(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     ),\n\u001b[1;32m    129\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# | code: true\n",
    "# | output: false\n",
    "\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation-report\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "evaluate_model_step = ProcessingStep(\n",
    "    name=\"evaluate-model\",\n",
    "    step_args=evaluation_processor.run(\n",
    "        inputs=[\n",
    "            # The first input is the test split that we generated on\n",
    "            # the first step of the pipeline when we split and\n",
    "            # transformed the data.\n",
    "            ProcessingInput(\n",
    "                source=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\",\n",
    "            ),\n",
    "            # The second input is the model that we generated on\n",
    "            # the Training or Tunning Step.\n",
    "            ProcessingInput(\n",
    "                source=model_assets,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            # The output is the evaluation report that we generated\n",
    "            # in the evaluation script.\n",
    "            ProcessingOutput(\n",
    "                output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"\n",
    "            ),\n",
    "        ],\n",
    "        code=f\"{CODE_FOLDER}/evaluation.py\",\n",
    "    ),\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config,\n",
    ")\n",
    "\n",
    "MODEL_PACKAGE_GROUP = \"penguins\"\n",
    "\n",
    "tensorflow_model = TensorFlowModel(\n",
    "    model_data=model_assets,\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                evaluate_model_step.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "                \"evaluation.json\",\n",
    "            ],\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name=\"register-model\",\n",
    "    step_args=tensorflow_model.register(\n",
    "        model_package_group_name=MODEL_PACKAGE_GROUP,\n",
    "        approval_status=\"Approved\",\n",
    "        model_metrics=model_metrics,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[config[\"instance_type\"]],\n",
    "        transform_instances=[config[\"instance_type\"]],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"TENSORFLOW\",\n",
    "        framework_version=config[\"framework_version\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Initialize a boto3 client for Lambda\n",
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "# Define the payload for the Lambda function\n",
    "payload = {\n",
    "    \"best_model_accuracy_default\": 0.5\n",
    "}\n",
    "\n",
    "# Invoke the Lambda function\n",
    "response = lambda_client.invoke(\n",
    "    FunctionName=\"arn:aws:lambda:us-east-2:992382774880:function:MlSchoolStack-ModelAccuraccyLambdaFunctionA882847A-axbrhl7xbLiM\",\n",
    "    InvocationType=\"RequestResponse\",\n",
    "    Payload=json.dumps(payload),\n",
    ")\n",
    "\n",
    "# Process the response from Lambda\n",
    "response_payload = json.loads(response['Payload'].read())\n",
    "response_payload_dict = json.loads(response_payload['body'])\n",
    "print(response_payload_dict)\n",
    "\n",
    "# Use the output from Lambda as the accuracy threshold\n",
    "accuracy_threshold = response_payload_dict[\"best_model_accuracy\"]\n",
    "\n",
    "latest_model_accuracy = JsonGet(\n",
    "    step_name=evaluate_model_step.name,\n",
    "    property_file=evaluation_report,\n",
    "    json_path=\"metrics.accuracy.value\",\n",
    ")\n",
    "\n",
    "fail_step = FailStep(\n",
    "    name=\"fail\",\n",
    "    error_message=Join(\n",
    "        on=\" \",\n",
    "        values=[\n",
    "            \"Execution failed because the model's accuracy was lower than\",\n",
    "            accuracy_threshold,\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "better_model_condition = ConditionGreaterThanOrEqualTo(\n",
    "    left=latest_model_accuracy, right=accuracy_threshold,\n",
    ")\n",
    "\n",
    "register_model_condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[better_model_condition],\n",
    "    if_steps=[register_model_step] if not LOCAL_MODE else [],\n",
    "    else_steps=[fail_step],\n",
    ")\n",
    "\n",
    "# TODO update these\n",
    "\n",
    "publish_best_model_step = ModelStep(\n",
    "    name=\"register-model\",\n",
    "    step_args=tensorflow_model.register(\n",
    "        model_package_group_name=MODEL_PACKAGE_GROUP,\n",
    "        approval_status=\"Approved\",\n",
    "        model_metrics=model_metrics,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[config[\"instance_type\"]],\n",
    "        transform_instances=[config[\"instance_type\"]],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"TENSORFLOW\",\n",
    "        framework_version=config[\"framework_version\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "best_model_condition = ConditionGreaterThanOrEqualTo(\n",
    "    # left=latest_model_accuracy, right=accuracy_threshold,\n",
    ")\n",
    "\n",
    "finish_evaluation_condition_step = ConditionStep(\n",
    "    name=\"publish-most-accurate-model\",\n",
    "    conditions=[best_model_condition],\n",
    "    if_steps=[publish_best_model_step] if not LOCAL_MODE else [],\n",
    "    else_steps=[fail_step],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f70bcd33-b499-4e2b-953e-94d1ed96c10a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded None to s3://mlschools-data-jerryb/session3-pipeline/code/e065caff8e1610ef2e01027f5cf131ad/sourcedir.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://mlschools-data-jerryb/session3-pipeline/code/2c207c809cb0e0e9a1d77e5247f961f9/runproc.sh\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded None to s3://mlschools-data-jerryb/session3-pipeline/code/e065caff8e1610ef2e01027f5cf131ad/sourcedir.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://mlschools-data-jerryb/session3-pipeline/code/2c207c809cb0e0e9a1d77e5247f961f9/runproc.sh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-2:992382774880:pipeline/session3-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '1b5a858c-999a-4231-9f3d-0a4d3f0c789b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1b5a858c-999a-4231-9f3d-0a4d3f0c789b',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '85',\n",
       "   'date': 'Thu, 15 Feb 2024 01:35:07 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | code: true\n",
    "# | output: false\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "\n",
    "pipeline_definition_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "\n",
    "session3_pipeline = Pipeline(\n",
    "    name=\"session3-pipeline\",\n",
    "    parameters=[dataset_location, epochs, accuracy_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        # tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "        train_model_step,\n",
    "        tune_model_step,\n",
    "        evaluate_model_step,\n",
    "        register_model_condition_step,\n",
    "        finish_evaluation_condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session3_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f656e",
   "metadata": {},
   "source": [
    "We can now start the pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36144169",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3b4126e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:us-east-2:992382774880:pipeline/session3-pipeline/execution/kyfedr9eogzg', sagemaker_session=<sagemaker.workflow.pipeline_context.PipelineSession object at 0x106b5a610>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "#| eval: false\n",
    "#| code: true\n",
    "#| output: false\n",
    "\n",
    "session3_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9418693c-ccd5-42b6-8ec4-04bb70fe213c",
   "metadata": {},
   "source": [
    "### Assignments\n",
    "\n",
    "-   <span style=\"padding:4px; line-height:30px; background-color: #f2a68a; color: #000;\"><strong>Assignment 3.1</strong></span> The evaluation script computes the accuracy of the model and exports it as part of the evaluation report. Extend the evaluation report by adding the precision and the recall of the model on each one of the classes.\n",
    "\n",
    "-   <span style=\"padding:4px; line-height:30px; background-color: #f2a68a; color: #000;\"><strong>Assignment 3.2</strong></span> Extend the evaluation script to test the model on each island separately. The evaluation report should contain the accuracy of the model on each island and the overall accuracy.\n",
    "\n",
    "-   <span style=\"padding:4px; line-height:30px; background-color: #f2a68a; color: #000;\"><strong>Assignment 3.3</strong></span> The Condition Step uses a hard-coded threshold value to determine if the model's accuracy is good enough to proceed. Modify the code so the pipeline uses the accuracy of the latest registered model version as the threshold. We want to register a new model version only if its performance is better than the previous version we registered.\n",
    "\n",
    "-   <span style=\"padding:4px; line-height:30px; background-color: #f2a68a; color: #000;\"><strong>Assignment 3.4</strong></span> The current pipeline uses either a Training Step or a Tuning Step to build a model. Modify the pipeline to use both steps at the same time. The evaluation script should evaluate the model coming from the Training Step and the best model coming from the Tuning Step and output the accuracy and location in S3 of the best model. You should modify the code to register the model assets specified in the evaluation report.\n",
    "\n",
    "-   <span style=\"padding:4px; line-height:30px; background-color: #f2a68a; color: #000;\"><strong>Assignment 3.5</strong></span> Pipeline steps can encounter exceptions. In some cases, retrying can resolve these issues. For this assignment, configure the Processing Step so it automatically retries the step a maximum of 5 times if it encounters an `InternalServerError`. Check the [Retry Policy for Pipeline Steps](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-retry-policy.html) documentation for more information."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:325223348818:studio-lifecycle-config/packages",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
