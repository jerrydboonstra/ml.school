{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a355287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2265b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/jerryobex/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import ipytest\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession, LocalPipelineSession\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat\n",
    "\n",
    "\n",
    "CODE_FOLDER = Path(\"code\")\n",
    "CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "INFERENCE_CODE_FOLDER = CODE_FOLDER / \"inference\"\n",
    "INFERENCE_CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.path.extend([f\"./{CODE_FOLDER}\", f\"./{INFERENCE_CODE_FOLDER}\"])\n",
    "\n",
    "DATA_FILEPATH = \"penguins.csv\"\n",
    "\n",
    "ipytest.autoconfig(raise_on_error=True)\n",
    "\n",
    "# By default, The SageMaker SDK logs events related to the default\n",
    "# configuration using the INFO level. To prevent these from spoiling\n",
    "# the output of this notebook cells, we can change the logging\n",
    "# level to ERROR instead.\n",
    "logging.getLogger(\"sagemaker.config\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3164a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LOCAL_MODE = False\n",
    "\n",
    "bucket = os.environ[\"BUCKET\"]\n",
    "role = os.environ[\"ROLE\"]\n",
    "\n",
    "S3_LOCATION = f\"s3://{bucket}/penguins\"\n",
    "\n",
    "architecture = !(uname -m)\n",
    "IS_APPLE_M_CHIP = architecture[0] == \"arm64\"\n",
    "\n",
    "\n",
    "pipeline_session = PipelineSession(default_bucket=bucket) if not LOCAL_MODE else None\n",
    "\n",
    "if LOCAL_MODE:\n",
    "    config = {\n",
    "        \"session\": LocalPipelineSession(default_bucket=bucket),\n",
    "        \"instance_type\": \"local\",\n",
    "        # We need to use a custom Docker image when we run the pipeline\n",
    "        # in Local Model on an ARM64 machine.\n",
    "        \"image\": \"sagemaker-tensorflow-toolkit-local\" if IS_APPLE_M_CHIP else None,\n",
    "    }\n",
    "else:\n",
    "    config = {\n",
    "        \"session\": pipeline_session,\n",
    "        \"instance_type\": \"ml.m5.xlarge\",\n",
    "        \"image\": None,\n",
    "    }\n",
    "\n",
    "config[\"framework_version\"] = \"2.11\"\n",
    "config[\"py_version\"] = \"py39\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "942a01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "iam_client = boto3.client(\"iam\")\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "USE_TUNING_STEP = not LOCAL_MODE\n",
    "# USE_TUNING_STEP = False and not LOCAL_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b18b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerryobex/proj/mlschool/.venv/lib/python3.9/site-packages/sagemaker/workflow/pipeline_context.py:297: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# | code: true\n",
    "# | output: false\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"15d\")\n",
    "\n",
    "# dataset_location = ParameterString(\n",
    "#     name=\"dataset_location\",\n",
    "#     default_value=f\"{S3_LOCATION}/data\",\n",
    "# )\n",
    "\n",
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=f\"{S3_LOCATION}/data\",\n",
    ")\n",
    "\n",
    "new_prep_processor = False\n",
    "\n",
    "processor = None\n",
    "\n",
    "if new_prep_processor:\n",
    "    # Specify the directory containing your `requirements.txt`\n",
    "    processor = FrameworkProcessor(\n",
    "        framework_version=\"1.2-1\",\n",
    "        estimator_cls=SKLearnProcessor,\n",
    "        base_job_name=\"preprocess-data\",\n",
    "        image_uri=retrieve(framework='sklearn', version='1.2-1', region=config[\"session\"].boto_region_name),\n",
    "        command=[\"python3\", \"-m\", \"preprocessor\"],\n",
    "        instance_type=config[\"instance_type\"],\n",
    "        instance_count=2,\n",
    "        role=role,\n",
    "        sagemaker_session=config[\"session\"],\n",
    "    )\n",
    "\n",
    "else:\n",
    "    processor = SKLearnProcessor(\n",
    "        base_job_name=\"preprocess-data\",\n",
    "        framework_version=\"1.2-1\",\n",
    "        # By default, a new account doesn't have access to `ml.m5.xlarge` instances.\n",
    "        # If you haven't requested a quota increase yet, you can use an\n",
    "        # `ml.t3.medium` instance type instead. This will work out of the box, but\n",
    "        # the Processing Job will take significantly longer than it should have.\n",
    "        # To get access to `ml.m5.xlarge` instances, you can request a quota\n",
    "        # increase under the Service Quotas section in your AWS account.\n",
    "        instance_type=config[\"instance_type\"],\n",
    "        instance_count=2,\n",
    "        role=role,\n",
    "        sagemaker_session=config[\"session\"],\n",
    "    )\n",
    "\n",
    "\n",
    "preprocessing_step = ProcessingStep(\n",
    "    name=\"preprocess-data\",\n",
    "    step_args=processor.run(\n",
    "        code=f\"{CODE_FOLDER}/preprocessor.py\",\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=dataset_location, destination=\"/opt/ml/processing/input\", s3_data_distribution_type=\"ShardedByS3Key\"\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"train\",\n",
    "                source=\"/opt/ml/processing/train\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/train\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"validation\",\n",
    "                source=\"/opt/ml/processing/validation\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/validation\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"test\",\n",
    "                source=\"/opt/ml/processing/test\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/test\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"model\",\n",
    "                source=\"/opt/ml/processing/model\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/model\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"train-baseline\",\n",
    "                source=\"/opt/ml/processing/train-baseline\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/train-baseline\",\n",
    "            ),\n",
    "            ProcessingOutput(\n",
    "                output_name=\"test-baseline\",\n",
    "                source=\"/opt/ml/processing/test-baseline\",\n",
    "                destination=f\"{S3_LOCATION}/preprocessing/test-baseline\",\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")\n",
    "\n",
    "\n",
    "epochs = ParameterInteger(name=\"epochs\", default_value=50)\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    base_job_name=\"training\",\n",
    "    entry_point=f\"{CODE_FOLDER}/train.py\",\n",
    "    # SageMaker will pass these hyperparameters as arguments\n",
    "    # to the entry point of the training script.\n",
    "    hyperparameters={\n",
    "        \"epochs\": epochs,  # Referencing the pipeline parameter\n",
    "        \"batch_size\": 32,\n",
    "        # \"learning_rate\": 0.01,\n",
    "        'learning_rate': ParameterFloat(0.01),\n",
    "    },\n",
    "    # SageMaker will track these metrics as part of the experiment\n",
    "    # associated to this pipeline. The metric definitions tells\n",
    "    # SageMaker how to parse the values from the Training Job logs.\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"accuracy\", \"Regex\": \"accuracy: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"},\n",
    "        {\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"},\n",
    "    ],\n",
    "    image_uri=config[\"image\"],\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    py_version=config[\"py_version\"],\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    disable_profiler=True,\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "train_model_step = TrainingStep(\n",
    "    name=\"train-model\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    "    # cache_config is optional, shown here as part of a complete example\n",
    "    cache_config=cache_config  # Assuming cache_config is defined elsewhere\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee3ab26-afa5-4ceb-9f7a-005d5fdea646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluation_old.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/evaluation_old.py\n",
    "#| label: evaluation-script\n",
    "#| echo: true\n",
    "#| output: false\n",
    "#| filename: evaluation.py\n",
    "#| code-line-numbers: true\n",
    "\n",
    "import json\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def evaluate(model_path, test_path, output_path):\n",
    "    X_test = pd.read_csv(Path(test_path) / \"test.csv\")\n",
    "    y_test = X_test.iloc[:, -1]  # Assuming the last column is the target\n",
    "    island_columns = X_test.columns[-4:-1]  # Last 3 columns are one-hot encoded islands, excluding the target\n",
    "    X_test.drop(X_test.columns[-1], axis=1, inplace=True)  # Drop target column only\n",
    "\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    model = keras.models.load_model(Path(model_path) / \"001\")\n",
    "    \n",
    "    predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "    overall_accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Overall Test Accuracy: {overall_accuracy}\")\n",
    "\n",
    "    precision = precision_score(y_test, predictions, average=None, zero_division=0)\n",
    "    recall = recall_score(y_test, predictions, average=None, zero_division=0)\n",
    "    \n",
    "    # Print overall precision and recall\n",
    "    print(\"Overall Precision by Class:\", precision)\n",
    "    print(\"Overall Recall by Class:\", recall)\n",
    "\n",
    "    island_accuracies = {}\n",
    "    for col in island_columns:\n",
    "        island_mask = X_test[col] == 1\n",
    "        y_island = y_test[island_mask]\n",
    "        if len(y_island) > 0:\n",
    "            island_predictions = np.argmax(model.predict(X_test[island_mask]), axis=-1)\n",
    "            island_accuracy = accuracy_score(y_island, island_predictions)\n",
    "            island_accuracies[col] = island_accuracy\n",
    "            print(f\"Accuracy for island {col}: {island_accuracy}\")\n",
    "        else:\n",
    "            island_accuracies[col] = None\n",
    "            print(f\"No samples for {col}.\")\n",
    "\n",
    "    evaluation_report = {\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": {\"value\": overall_accuracy},\n",
    "            \"island_accuracies\": island_accuracies,\n",
    "            \"precision\": {f\"class_{i}\": val for i, val in enumerate(precision)},\n",
    "            \"recall\": {f\"class_{i}\": val for i, val in enumerate(recall)},\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=\"/opt/ml/processing/model/\", \n",
    "        test_path=\"/opt/ml/processing/test/\",\n",
    "        output_path=\"/opt/ml/processing/evaluation/\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a2540d8-278a-4953-bc54-0469d154427d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 1.2286 - accuracy: 0.2050 - val_loss: 1.2092 - val_accuracy: 0.1961 - 166ms/epoch - 21ms/step\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Validation accuracy: 0.19607843137254902\n",
      "INFO:tensorflow:Assets written to: /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmpcf245y8e/model/001/assets\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Overall Test Accuracy: 0.19607843137254902\n",
      "Overall Precision by Class: [1.         0.20454545 0.        ]\n",
      "Overall Recall by Class: [0.04347826 0.9        0.        ]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Accuracy for island 0.0: 0.0\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Accuracy for island 1.0: 0.5555555555555556\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Accuracy for island 0.0.1: 0.0\n",
      "\u001b[32m.\u001b[0m8/8 - 0s - loss: 1.0576 - accuracy: 0.3473 - val_loss: 0.9865 - val_accuracy: 0.5490 - 149ms/epoch - 19ms/step\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Validation accuracy: 0.5490196078431373\n",
      "INFO:tensorflow:Assets written to: /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmpc97uaz2c/model/001/assets\n",
      "2/2 [==============================] - 0s 889us/step\n",
      "Overall Test Accuracy: 0.35294117647058826\n",
      "Overall Precision by Class: [1.         0.05263158 0.44444444]\n",
      "Overall Recall by Class: [0.2173913  0.1        0.66666667]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Accuracy for island 0.0: 0.52\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Accuracy for island 1.0: 0.16666666666666666\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Accuracy for island 0.0.1: 0.25\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 1.18s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -s\n",
    "#| code-fold: true\n",
    "#| output: false\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import pytest\n",
    "import tempfile\n",
    "import joblib\n",
    "\n",
    "from preprocessor import preprocess\n",
    "from train import train\n",
    "from evaluation_old import evaluate\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "    \n",
    "    directory = Path(directory)\n",
    "    \n",
    "    preprocess(base_directory=directory)\n",
    "    \n",
    "    train(\n",
    "        model_directory=directory / \"model\",\n",
    "        train_path=directory / \"train\", \n",
    "        validation_path=directory / \"validation\",\n",
    "        epochs=1\n",
    "    )\n",
    "    \n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(directory / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(directory / \"model\" / \"001\", arcname=\"001\")\n",
    "        \n",
    "    evaluate(\n",
    "        model_path=directory, \n",
    "        test_path=directory / \"test\",\n",
    "        output_path=directory / \"evaluation\",\n",
    "    )\n",
    "\n",
    "    yield directory / \"evaluation\"\n",
    "    \n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "\n",
    "def test_evaluate_generates_evaluation_report(directory):\n",
    "    output = os.listdir(directory)\n",
    "    assert \"evaluation.json\" in output\n",
    "\n",
    "\n",
    "def test_evaluation_report_contains_accuracy(directory):\n",
    "    with open(directory / \"evaluation.json\", 'r') as file:\n",
    "        report = json.load(file)\n",
    "        \n",
    "    assert \"metrics\" in report\n",
    "    assert \"accuracy\" in report[\"metrics\"]\n",
    "    assert \"island_accuracies\" in report[\"metrics\"]\n",
    "    assert \"precision\" in report[\"metrics\"]\n",
    "    assert \"recall\" in report[\"metrics\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f03142d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/evaluation.py\n",
    "#| label: evaluation-script\n",
    "#| echo: true\n",
    "#| output: false\n",
    "#| filename: evaluation.py\n",
    "#| code-line-numbers: true\n",
    "\n",
    "import json\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def load_and_evaluate_model(model_path, X_test, y_test, island_columns):\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    model = keras.models.load_model(Path(model_path) / \"001\")\n",
    "    \n",
    "    predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "    overall_accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    precision = precision_score(y_test, predictions, average=None, zero_division=0)\n",
    "    recall = recall_score(y_test, predictions, average=None, zero_division=0)\n",
    "    \n",
    "    island_accuracies = {}\n",
    "    for col in island_columns:\n",
    "        island_mask = X_test[col] == 1\n",
    "        y_island = y_test[island_mask]\n",
    "        if len(y_island) > 0:\n",
    "            island_predictions = np.argmax(model.predict(X_test[island_mask]), axis=-1)\n",
    "            island_accuracy = accuracy_score(y_island, island_predictions)\n",
    "            island_accuracies[col] = island_accuracy\n",
    "        else:\n",
    "            island_accuracies[col] = None\n",
    "    \n",
    "    return overall_accuracy, island_accuracies, precision, recall\n",
    "\n",
    "def evaluate_models(trained_model_path, tuned_model_path, test_path, output_path):\n",
    "    X_test = pd.read_csv(Path(test_path) / \"test.csv\")\n",
    "    y_test = X_test.iloc[:, -1]  # Assuming the last column is the target\n",
    "    island_columns = X_test.columns[-4:-1]  # Last 3 columns are one-hot encoded islands, excluding the target\n",
    "    X_test.drop(X_test.columns[-1], axis=1, inplace=True)  # Drop target column only\n",
    "    \n",
    "    trained_model_accuracy, trained_island_accuracies, trained_precision, trained_recall = load_and_evaluate_model(trained_model_path, X_test, y_test, island_columns)\n",
    "    tuned_model_accuracy, tuned_island_accuracies, tuned_precision, tuned_recall = load_and_evaluate_model(tuned_model_path, X_test, y_test, island_columns)\n",
    "    \n",
    "    best_model, best_accuracy = (\"tuned\", tuned_model_accuracy) if tuned_model_accuracy > trained_model_accuracy else (\"trained\", trained_model_accuracy)\n",
    "    best_model_path = tuned_model_path if best_model == \"tuned\" else trained_model_path\n",
    "    \n",
    "    evaluation_report = {\n",
    "        \"best_model\": best_model,\n",
    "        \"best_model_accuracy\": best_accuracy,\n",
    "        \"best_model_path\": str(best_model_path),\n",
    "        \"comparison\": {\n",
    "            \"trained_model_accuracy\": trained_model_accuracy,\n",
    "            \"tuned_model_accuracy\": tuned_model_accuracy,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_models(\n",
    "        trained_model_path=\"/opt/ml/processing/model/\",\n",
    "        tuned_model_path=\"/opt/ml/processing/model/\",\n",
    "        test_path=\"/opt/ml/processing/test/\",\n",
    "        output_path=\"/opt/ml/processing/evaluation/\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6bf0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 1.3973 - accuracy: 0.2218 - val_loss: 1.3197 - val_accuracy: 0.2549 - 134ms/epoch - 17ms/step\n",
      "2/2 [==============================] - 0s 874us/step\n",
      "Validation accuracy: 0.2549019607843137\n",
      "INFO:tensorflow:Assets written to: /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmp0csvtmys/model/001/assets\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2b97f54c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "\u001b[32m.\u001b[0m8/8 - 0s - loss: 1.0948 - accuracy: 0.3138 - val_loss: 1.0675 - val_accuracy: 0.4510 - 137ms/epoch - 17ms/step\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Validation accuracy: 0.45098039215686275\n",
      "INFO:tensorflow:Assets written to: /var/folders/5k/bjy1b7pd2wxctw1dtvx0l2fc0000gn/T/tmpkvngy4dx/model/001/assets\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 942us/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 1.44s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -s\n",
    "#| code-fold: true\n",
    "#| output: false\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import pytest\n",
    "import tempfile\n",
    "import joblib\n",
    "\n",
    "from preprocessor import preprocess\n",
    "from train import train\n",
    "from evaluation import evaluate_models\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"function\", autouse=False)\n",
    "def directory():\n",
    "    directory = tempfile.mkdtemp()\n",
    "    input_directory = Path(directory) / \"input\"\n",
    "    input_directory.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(DATA_FILEPATH, input_directory / \"data.csv\")\n",
    "    \n",
    "    directory = Path(directory)\n",
    "    \n",
    "    preprocess(base_directory=directory)\n",
    "    \n",
    "    train(\n",
    "        model_directory=directory / \"model\",\n",
    "        train_path=directory / \"train\", \n",
    "        validation_path=directory / \"validation\",\n",
    "        epochs=1\n",
    "    )\n",
    "    \n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(directory / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(directory / \"model\" / \"001\", arcname=\"001\")\n",
    "        \n",
    "    # def evaluate_models(trained_model_path, tuned_model_path, test_path, output_path):\n",
    "    evaluate_models(\n",
    "        trained_model_path=directory / \"model\",  # Path to the trained model\n",
    "        tuned_model_path=directory / \"model\",  # Path to the tuned model (simulated as the same for this test)\n",
    "        test_path=directory / \"test\",\n",
    "        output_path=directory / \"evaluation\",\n",
    "    )\n",
    "\n",
    "    yield directory / \"evaluation\"\n",
    "    \n",
    "    shutil.rmtree(directory)\n",
    "\n",
    "\n",
    "def test_evaluate_generates_evaluation_report(directory):\n",
    "    output = os.listdir(directory)\n",
    "    assert \"evaluation.json\" in output\n",
    "\n",
    "\n",
    "def test_evaluation_report_contains_accuracy(directory):\n",
    "    with open(directory / \"evaluation.json\", 'r') as file:\n",
    "        report = json.load(file)\n",
    "        \n",
    "    assert \"best_model\" in report\n",
    "    assert \"best_model_accuracy\" in report\n",
    "    assert \"best_model_path\" in report\n",
    "    assert \"comparison\" in report\n",
    "    assert \"trained_model_accuracy\" in report[\"comparison\"]\n",
    "    assert \"tuned_model_accuracy\" in report[\"comparison\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f19e15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerryobex/proj/mlschool/.venv/lib/python3.9/site-packages/sagemaker/workflow/pipeline_context.py:297: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# | code: true\n",
    "# | output: false\n",
    "\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter, CategoricalParameter\n",
    "from sagemaker.tensorflow import TensorFlowProcessor\n",
    "\n",
    "evaluation_processor = TensorFlowProcessor(\n",
    "    base_job_name=\"evaluation-processor\",\n",
    "    image_uri=config[\"image\"],\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    py_version=config[\"py_version\"],\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "# target_metric_name = \"val_accuracy\"\n",
    "# objective_type=\"Maximize\",\n",
    "target_metric_name = \"loss\"\n",
    "objective_type=\"Minimize\",\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name=target_metric_name,\n",
    "    objective_type=objective_type,\n",
    "    hyperparameter_ranges={\n",
    "        'learning_rate': ContinuousParameter(0.001, 0.2),\n",
    "        \"epochs\": IntegerParameter(10, 50),\n",
    "    },\n",
    "    metric_definitions=[{\"Name\": target_metric_name, \"Regex\": f\"{target_metric_name}: ([0-9\\\\.]+)\"}],\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3,\n",
    ")\n",
    "\n",
    "tune_model_step = TuningStep(\n",
    "    name=\"tune-model\",\n",
    "    step_args=tuner.fit(\n",
    "        inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")\n",
    "model_assets = train_model_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "\n",
    "tuned_model_assets = tune_model_step.get_top_model_s3_uri(\n",
    "    top_k=0, s3_bucket=config[\"session\"].default_bucket()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9773a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve accuracy metric from the latest model package.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_payload_dict)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Use the output from Lambda as the accuracy threshold\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m accuracy_threshold \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_payload_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_model_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    126\u001b[0m latest_model_accuracy \u001b[38;5;241m=\u001b[39m JsonGet(\n\u001b[1;32m    127\u001b[0m     step_name\u001b[38;5;241m=\u001b[39mevaluate_model_step\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    128\u001b[0m     property_file\u001b[38;5;241m=\u001b[39mevaluation_report,\n\u001b[1;32m    129\u001b[0m     json_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics.accuracy.value\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    132\u001b[0m fail_step \u001b[38;5;241m=\u001b[39m FailStep(\n\u001b[1;32m    133\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    134\u001b[0m     error_message\u001b[38;5;241m=\u001b[39mJoin(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m     ),\n\u001b[1;32m    141\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# | code: true\n",
    "# | output: true\n",
    "\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation-report\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "evaluate_model_step = ProcessingStep(\n",
    "    name=\"evaluate-model\",\n",
    "    # evaluate_models(\n",
    "    #     trained_model_path=\"/opt/ml/processing/trained_model/\",\n",
    "    #     tuned_model_path=\"/opt/ml/processing/tuned_model/\",\n",
    "    #     test_path=\"/opt/ml/processing/test/\",\n",
    "    #     output_path=\"/opt/ml/processing/evaluation/\"\n",
    "    # )\n",
    "    step_args=evaluation_processor.run(\n",
    "        inputs=[\n",
    "            # The first input is the test split that we generated on\n",
    "            # the first step of the pipeline when we split and\n",
    "            # transformed the data.\n",
    "            ProcessingInput(\n",
    "                source=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\",\n",
    "            ),\n",
    "            # The second input is the model that we generated on\n",
    "            # the Training Step.\n",
    "            ProcessingInput(\n",
    "                source=model_assets,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "            # The third input is the tuned model that we generated on\n",
    "            # the Tuning Step.\n",
    "            ProcessingInput(\n",
    "                source=tuned_model_assets,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            # The output is the evaluation report that we generated\n",
    "            # in the evaluation script.\n",
    "            ProcessingOutput(\n",
    "                output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"\n",
    "            ),\n",
    "        ],\n",
    "        code=f\"{CODE_FOLDER}/evaluation.py\",\n",
    "    ),\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config,\n",
    ")\n",
    "\n",
    "MODEL_PACKAGE_GROUP = \"penguins\"\n",
    "\n",
    "tensorflow_model = TensorFlowModel(\n",
    "    model_data=model_assets,\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                evaluate_model_step.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "                \"evaluation.json\",\n",
    "            ],\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name=\"register-model\",\n",
    "    step_args=tensorflow_model.register(\n",
    "        model_package_group_name=MODEL_PACKAGE_GROUP,\n",
    "        approval_status=\"Approved\",\n",
    "        model_metrics=model_metrics,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[config[\"instance_type\"]],\n",
    "        transform_instances=[config[\"instance_type\"]],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"TENSORFLOW\",\n",
    "        framework_version=config[\"framework_version\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Initialize a boto3 client for Lambda\n",
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "# Define the payload for the Lambda function\n",
    "payload = {\n",
    "    \"best_model_accuracy_default\": 0.5\n",
    "}\n",
    "\n",
    "# Invoke the Lambda function\n",
    "response = lambda_client.invoke(\n",
    "    FunctionName=\"arn:aws:lambda:us-east-2:992382774880:function:MlSchoolStack-ModelAccuraccyLambdaFunctionA882847A-axbrhl7xbLiM\",\n",
    "    InvocationType=\"RequestResponse\",\n",
    "    Payload=json.dumps(payload),\n",
    ")\n",
    "\n",
    "# Process the response from Lambda\n",
    "response_payload = json.loads(response['Payload'].read())\n",
    "response_payload_dict = json.loads(response_payload['body'])\n",
    "print(response_payload_dict)\n",
    "\n",
    "# Use the output from Lambda as the accuracy threshold\n",
    "accuracy_threshold = response_payload_dict[\"best_model_accuracy\"] if \"best_model_accuracy\" in response_payload_dict else 0.5\n",
    "\n",
    "latest_model_accuracy = JsonGet(\n",
    "    step_name=evaluate_model_step.name,\n",
    "    property_file=evaluation_report,\n",
    "    json_path=\"metrics.accuracy.value\",\n",
    ")\n",
    "\n",
    "fail_step = FailStep(\n",
    "    name=\"fail\",\n",
    "    error_message=Join(\n",
    "        on=\" \",\n",
    "        values=[\n",
    "            \"Execution failed because the model's accuracy was lower than\",\n",
    "            accuracy_threshold,\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "better_model_condition = ConditionGreaterThanOrEqualTo(\n",
    "    left=latest_model_accuracy, right=accuracy_threshold,\n",
    ")\n",
    "\n",
    "register_model_condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[better_model_condition],\n",
    "    if_steps=[register_model_step] if not LOCAL_MODE else [],\n",
    "    else_steps=[fail_step],\n",
    ")\n",
    "\n",
    "publish_best_model_step = ModelStep(\n",
    "    name=\"register-model\",\n",
    "    step_args=tensorflow_model.register(\n",
    "        model_package_group_name=MODEL_PACKAGE_GROUP,\n",
    "        approval_status=\"Approved\",\n",
    "        model_metrics=model_metrics,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[config[\"instance_type\"]],\n",
    "        transform_instances=[config[\"instance_type\"]],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"TENSORFLOW\",\n",
    "        framework_version=config[\"framework_version\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "finish_evaluation_condition_step = ConditionStep(\n",
    "    name=\"publish-most-accurate-model\",\n",
    "    conditions=[better_model_condition],\n",
    "    if_steps=[publish_best_model_step] if not LOCAL_MODE else [],\n",
    "    else_steps=[fail_step],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bcd33-b499-4e2b-953e-94d1ed96c10a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# | code: true\n",
    "# | output: false\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "\n",
    "pipeline_definition_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "\n",
    "session3_pipeline = Pipeline(\n",
    "    name=\"session3-pipeline\",\n",
    "    parameters=[dataset_location, epochs, accuracy_threshold],\n",
    "    steps=[\n",
    "        preprocessing_step,\n",
    "        # tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "        train_model_step,\n",
    "        tune_model_step,\n",
    "        evaluate_model_step,\n",
    "        register_model_condition_step,\n",
    "        finish_evaluation_condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session3_pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f656e",
   "metadata": {},
   "source": [
    "We can now start the pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36144169",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#0066cc;\"><strong>Note:</strong> \n",
    "    The <code>%%script</code> cell magic is a convenient way to prevent the notebook from executing a specific cell. If you want to run the cell, comment out the line containing the <code>%%script</code> cell magic.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b4126e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "#| eval: false\n",
    "#| code: true\n",
    "#| output: false\n",
    "\n",
    "session3_pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9418693c-ccd5-42b6-8ec4-04bb70fe213c",
   "metadata": {},
   "source": [
    "### Assignments\n",
    "\n",
    "-   <span style=\"padding:4px; line-height:30px; background-color: #f2a68a; color: #000;\"><strong>Assignment 3.1</strong></span> The evaluation script computes the accuracy of the model and exports it as part of the evaluation report. Extend the evaluation report by adding the precision and the recall of the model on each one of the classes.\n",
    "\n",
    "-   <span style=\"padding:4px; line-height:30px; background-color: #f2a68a; color: #000;\"><strong>Assignment 3.2</strong></span> Extend the evaluation script to test the model on each island separately. The evaluation report should contain the accuracy of the model on each island and the overall accuracy.\n",
    "\n",
    "-   <span style=\"padding:4px; line-height:30px; background-color: #f2a68a; color: #000;\"><strong>Assignment 3.3</strong></span> The Condition Step uses a hard-coded threshold value to determine if the model's accuracy is good enough to proceed. Modify the code so the pipeline uses the accuracy of the latest registered model version as the threshold. We want to register a new model version only if its performance is better than the previous version we registered.\n",
    "\n",
    "-   <span style=\"padding:4px; line-height:30px; background-color: #f2a68a; color: #000;\"><strong>Assignment 3.4</strong></span> The current pipeline uses either a Training Step or a Tuning Step to build a model. Modify the pipeline to use both steps at the same time. The evaluation script should evaluate the model coming from the Training Step and the best model coming from the Tuning Step and output the accuracy and location in S3 of the best model. You should modify the code to register the model assets specified in the evaluation report.\n",
    "\n",
    "-   <span style=\"padding:4px; line-height:30px; background-color: #f2a68a; color: #000;\"><strong>Assignment 3.5</strong></span> Pipeline steps can encounter exceptions. In some cases, retrying can resolve these issues. For this assignment, configure the Processing Step so it automatically retries the step a maximum of 5 times if it encounters an `InternalServerError`. Check the [Retry Policy for Pipeline Steps](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-retry-policy.html) documentation for more information."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:325223348818:studio-lifecycle-config/packages",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
